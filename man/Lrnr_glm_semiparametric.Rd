% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_glm_semiparametric.R
\docType{class}
\name{Lrnr_glm_semiparametric}
\alias{Lrnr_glm_semiparametric}
\title{Semiparametric Generalized Linear Models}
\format{
An \code{\link[R6]{R6Class}} object inheriting from
\code{\link{Lrnr_base}}.
}
\value{
A learner object inheriting from \code{\link{Lrnr_base}} with
methods for training and prediction. For a full list of learner
functionality, see the complete documentation of \code{\link{Lrnr_base}}.
}
\description{
This learner provides fitting procedures for semiparametric generalized linear models using a user-given baseline learner and
\code{\link[stats]{glm.fit}}. It supports models of the form \verb{linkfun(E[Y|A,W]) = linkfun(E[Y|A=0,W]) + A * f(W)} where \code{A} is a binary or continuous interaction variable,
and \code{f(W)} is a user-specified parametric function (e.g. \code{f(W) = model.matrix(formula_sp, W)}). The baseline function \verb{E[Y|A=0,W]} is fit using a user-specified Learner (possibly pooled over values of \code{A} and then projected onto the semiparametric model).
}
\section{Parameters}{

\describe{
\item{\code{formula_sp}}{ A \code{\link{formula}} object specifying the parametric component of the semiparametric model.}
\item{\code{lrnr_baseline}}{A baseline learner for estimation of the nonparametric component. This can be pooled or unpooled by specifying \code{return_matrix_predictions}}
\item{\code{interaction_variable = "A"}}{A interaction variable name (that can be found in \code{training_task$data}) to multiply by the design matrix generated by \code{formula_sp}. If NULL then the interaction variable is treated identically \code{1}.
In many applications, this will be the name of a binary treatment variable (e.g. \code{A}).}
\item{\code{family = NULL}}{A family object whose link function specifies the type of semiparametric model (e.g. partially-linear least-squares (\code{\link{gaussian}), partially-linear logistic regression (\code{\link{binomial}), partially-linear log-linear regression (\code{\link{poisson}) }
  \item{\code{append_interaction_matrix = TRUE}}{Whether \code{lrnr_baseline} should be fit on `cbind(task$X,A*V)` where `A` is the interaction variable and `V` is the design matrix obtained from \code{formula_sp}.
  Note, if `append_interaction_matrix = TRUE`, the resulting estimator will be projected onto the semiparametric model using \code{glm.fit}.
  If this is FALSE and \code{interaction_variable} is binary then the semiparametric model is learned by stratifying on \code{interaction_variable}.
  Specifically, if FALSE, \code{lrnr_baseline} is used to estimate `E[Y|A=0,W]` by subsetting to only observations with `A = 0`.
  In the binary case, setting `append_interaction_matrix = TRUE` allows one to pool the learning across treatment arms and allows additive models to perform well.  }
  \item{\code{return_matrix_predictions = FALSE}}{Only used if \code{interaction_variable} is binary. Whether to return a matrix output with three columns being `E[Y|A=0,W], E[Y|A=1,W], E[Y|A,W]`.}
 \item{\code{...}}{Not used.}
}
}

\examples{
library(glmnet)
n <- 200
W <- runif(n, -1, 1)
A <- rbinom(n, 1, plogis(W))
Y_continuous <- rnorm(n, mean = A + W, sd = 0.3)
Y_binary <- rbinom(n, 1, plogis(A + W))
Y_count <- rpois(n, exp(A + W))
data <- data.table(W, A, Y_continuous, Y_binary, Y_count)

# Make tasks
task_continuous <- sl3_Task$new(data, covariates = c("A", "W"), outcome = "Y_continuous")
task_binary <- sl3_Task$new(data, covariates = c("A", "W"), outcome = "Y_binary")
task_count <- sl3_Task$new(data, covariates = c("A", "W"), outcome = "Y_count", outcome_type = "continuous")

formula_sp <- ~ 1 + W

# fit partially-linear least-squares regression with `append_interaction_matrix = TRUE`
set.seed(100)
lrnr_baseline <- Lrnr_glmnet$new()
family <- gaussian()
lrnr_glm_sp_gaussian <- Lrnr_glm_semiparametric$new(formula_sp = formula_sp, family = family, lrnr_baseline = lrnr_baseline, interaction_variable = "A", append_interaction_matrix = TRUE)
lrnr_glm_sp_gaussian <- lrnr_glm_sp_gaussian$train(task_continuous)
preds <- lrnr_glm_sp_gaussian$predict(task_continuous)
beta <- lrnr_glm_sp_gaussian$fit_object$coefficients
## In this case, since `append_interaction_matrix = TRUE`, it is equivalent to:
V <- model.matrix(formula_sp, task_continuous$data)
X <- cbind(task_continuous$data[["W"]], task_continuous$data[["A"]] * V)
X0 <- cbind(task_continuous$data[["W"]], 0 * V)
colnames(X) <- c("W", "A", "A*W")
Y <- task_continuous$Y
set.seed(100)
beta_equiv <- coef(cv.glmnet(X, Y, family = "gaussian"), s = "lambda.min")[c(3, 4)]
## Actually, the glmnet fit is projected onto the semiparametric model with glm.fit (no effect in this case)
print(beta - beta_equiv)

# fit partially-linear least-squares regression with `append_interaction_matrix = FALSE`
set.seed(100)
lrnr_baseline <- Lrnr_glm$new(family = gaussian())
family <- gaussian()
lrnr_glm_sp_gaussian <- Lrnr_glm_semiparametric$new(formula_sp = formula_sp, family = family, lrnr_baseline = lrnr_baseline, interaction_variable = "A", append_interaction_matrix = FALSE)
lrnr_glm_sp_gaussian <- lrnr_glm_sp_gaussian$train(task_continuous)
preds <- lrnr_glm_sp_gaussian$predict(task_continuous)
beta <- lrnr_glm_sp_gaussian$fit_object$coefficients
## In this case, since `append_interaction_matrix = TRUE`, it is equivalent to:
## Subset to baseline treatment arm
subset_to <- task_continuous$data[["A"]] == 0

V <- model.matrix(formula_sp, task_continuous$data)
X <- cbind(rep(1, n), task_continuous$data[["W"]])
Y <- task_continuous$Y
set.seed(100)
beta_Y0W <- lrnr_glm_sp_gaussian$fit_object$lrnr_baseline$fit_object$coefficients
beta_Y0W_equiv <- coef(glm.fit(X[subset_to, , drop = F], Y[subset_to], family = gaussian())) # Subset to baseline treatment arm
EY0 <- X \%*\% beta_Y0W
beta_equiv <- coef(glm.fit(A * V, Y, offset = EY0, family = gaussian()))
print(beta_Y0W - beta_Y0W_equiv)
print(beta - beta_equiv)

# fit partially-linear logistic regression
lrnr_baseline <- Lrnr_glmnet$new()
family <- binomial()
lrnr_glm_sp_binomial <- Lrnr_glm_semiparametric$new(formula_sp = formula_sp, family = family, lrnr_baseline = lrnr_baseline, interaction_variable = "A", append_interaction_matrix = TRUE)
lrnr_glm_sp_binomial <- lrnr_glm_sp_binomial$train(task_binary)
preds <- lrnr_glm_sp_binomial$predict(task_binary)
beta <- lrnr_glm_sp_binomial$fit_object$coefficients

# fit partially-linear log-link (relative-risk) regression
lrnr_baseline <- Lrnr_glmnet$new(family = "poisson") # This setting requires that lrnr_baseline predicts nonnegative values. It is recommended to use poisson regression based learners.
family <- poisson()
lrnr_glm_sp_binomial <- Lrnr_glm_semiparametric$new(formula_sp = formula_sp, family = family, lrnr_baseline = lrnr_baseline, interaction_variable = "A", append_interaction_matrix = TRUE)
lrnr_glm_sp_binomial <- lrnr_glm_sp_binomial$train(task_count)
preds <- lrnr_glm_sp_binomial$predict(task_count)
beta <- lrnr_glm_sp_binomial$fit_object$coefficients

#
}
\concept{Learners}
\keyword{data}
